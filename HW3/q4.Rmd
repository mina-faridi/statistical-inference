---
title: "HW3 q4"
output: html_notebook
---

a)
The Chi-Square Test of Independence determines whether there is an association between categorical variables (i.e., whether the variables are independent or related). It is a nonparametric test.
![](images/paste-F57662CB.png){width="311"}

b)

data must meet the following requirements:

1.  Two categorical variables.

2.  Two or more categories (groups) for each variable.

3.  Independence of observations.

    -   There is no relationship between the subjects in each group.

    -   The categorical variables are not "paired" in any way (e.g. pre-test/post-test observations).

4.  Relatively large sample size.

    -   Expected frequencies for each cell are at least 1.

    -   Expected frequencies should be at least 5 for the majority (80%) of the cells.

all of these conditions are satisfied.

c) chi-square is 82.81

```{r}
table <- matrix(nrow=3, ncol=5, byrow=TRUE)

table[1,] = c('23.7%', '25.9%', '25.9%', '24.5%', '100%')
table[2,] = c(147, 110, 52, 50, 359)
table[3,] = c(359 * 23.7 /100, 0, 359 * 25.9 /100, 0, 359 * 25.9 /100, 0, 359 * 24.5 /100, 0, 359)
table
chi_square = 0
for(i in 1:ncol(table))
{ 
  chi_square = chi_square
            +((strtoi(table[3 , i])-strtoi(table[2 , i]))^2/strtoi(table[3,i]))
}
chi_square
```

by checking the chart we see that the p-value is very small and should be less than 0.005

d)

```{r}
pchisq(chi_square,3,lower.tail=FALSE)

```

e) p value is very small and so the null hypothesis is rejected with high probability. and the two distributions are not the same.
